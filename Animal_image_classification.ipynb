{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c1a84-9d0d-4a88-be37-1ce20b0b4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Bobby\\Documents\\Animal_Classification\\Animal Classification\\dataset\"\n",
    "\n",
    "\n",
    "train_dataset = image_dataset_from_directory(dataset_path,\n",
    "                                             validation_split=0.2, \n",
    "                                             subset=\"training\",\n",
    "                                             seed=123,\n",
    "                                             image_size=(224, 224),\n",
    "                                             batch_size=32)\n",
    "\n",
    "val_dataset = image_dataset_from_directory(dataset_path,\n",
    "                                           validation_split=0.2, \n",
    "                                           subset=\"validation\",\n",
    "                                           seed=123,\n",
    "                                           image_size=(224, 224),\n",
    "                                           batch_size=32)\n",
    "\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e15d76-e35d-4646-a3a3-3c52fe3b224c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2a8b0-d10e-491f-8d39-39cfb752c7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4699e75-df86-4b8f-a03c-e308eda8dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2)\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cc4e3-2aec-4d2f-a1b3-76fae6a8e0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c145f15-a26d-4a10-b576-6c264c2cb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    data_augmentation,  \n",
    "    base_model,  \n",
    "    GlobalAveragePooling2D(),  \n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),  \n",
    "    Dense(15, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0bed3-dda7-4ff5-9f2b-d1e0f22363e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62fd14-f05c-4f37-b61d-7f0c4f8e9d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c593e-d123-44c9-bfc5-829ff3dfe03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562163eb-60f8-41a4-a3bd-8cfaf78a2712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808bc71-1bb6-404b-9215-0361b03f9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Bobby\\Documents\\Animal_Classification\\Animal Classification\\dataset\"\n",
    "\n",
    "class_folders = os.listdir(dataset_path)\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(dataset_path, class_folder)\n",
    "\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "        \n",
    "    image_files = [file for file in os.listdir(class_path) if file.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(class_path, img_name)  \n",
    "      \n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "       \n",
    "        prediction = model.predict(img_array)\n",
    "        pred_class = class_names[np.argmax(prediction)]\n",
    "\n",
    "        print(f\"ðŸ”¹ Processing Image: {img_path} | Predicted Class: {pred_class}\")\n",
    "\n",
    "       \n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Actual: {class_folder}\\nPredicted: {pred_class}\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010fcb0c-ef2d-469f-a36e-1328d6efa7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a88b03-5fbc-49e7-ba1e-83b8c70b6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)  \n",
    "model.save(\"animal_model.keras\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba9ffb-486c-4e43-a08c-6c1b8334a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"animal_model.h5\", save_format=\"h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600b9a3-0ebc-4c10-b510-26bbccf025c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a690a-c3f8-4a8e-a2c4-03b2ad785d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001da2b-7c10-40bc-be53-268459e2ff4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf8bfa-7212-4e3f-bece-c8d1367f6014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffeddc-c837-455e-974c-0a2c4c53dd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
